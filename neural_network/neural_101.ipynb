{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5f030d",
   "metadata": {},
   "source": [
    "Learn from \n",
    "[Learn to build a neural network from scratch (Medium article)](https://medium.com/@waadlingaadil/learn-to-build-a-neural-network-from-scratch-yes-really-cac4ca457efc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0792f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc4c67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 / input layer size 2\n",
      "layer 1 size 3\n",
      "layer 2 size 3\n",
      "layer 3 size 1\n"
     ]
    }
   ],
   "source": [
    "n = [2, 3, 3, 1]\n",
    "print(\"layer 0 / input layer size\", n[0])\n",
    "print(\"layer 1 size\", n[1])\n",
    "print(\"layer 2 size\", n[2])\n",
    "print(\"layer 3 size\", n[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47addbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(n[1], n[0])\n",
    "W2 = np.random.randn(n[2], n[1])\n",
    "W3 = np.random.randn(n[3], n[2])\n",
    "b1 = np.random.randn(n[1], 1)\n",
    "b2 = np.random.randn(n[2], 1)\n",
    "b3 = np.random.randn(n[3], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf75ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16306223,  0.22947171],\n",
       "       [-0.76147198, -1.02245648],\n",
       "       [-1.25507166,  0.65804714]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501787c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for layer 1 shape: (3, 2)\n",
      "Weights for layer 2 shape: (3, 3)\n",
      "Weights for layer 3 shape: (1, 3)\n",
      "bias for layer 1 shape: (3, 1)\n",
      "bias for layer 2 shape: (3, 1)\n",
      "bias for layer 3 shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights for layer 1 shape:\", W1.shape)\n",
    "print(\"Weights for layer 2 shape:\", W2.shape)\n",
    "print(\"Weights for layer 3 shape:\", W3.shape)\n",
    "print(\"bias for layer 1 shape:\", b1.shape)\n",
    "print(\"bias for layer 2 shape:\", b2.shape)\n",
    "print(\"bias for layer 3 shape:\", b3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2afd1503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [150, 70],\n",
    "    [254, 73],\n",
    "    [312, 68],\n",
    "    [120, 60],\n",
    "    [154, 61],\n",
    "    [212, 65],\n",
    "    [216, 67],\n",
    "    [145, 67],\n",
    "    [184, 64],\n",
    "    [130, 69]\n",
    "])\n",
    "\n",
    "print(X.shape) # prints (10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665056bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10)\n"
     ]
    }
   ],
   "source": [
    "A0 = X.T\n",
    "print(A0.shape) # prints (2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49d5d00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([\n",
    "    0,\n",
    "    1, \n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    0\n",
    "])\n",
    "m = 10\n",
    "\n",
    "# we need to reshape to a n^[3] x m matrix\n",
    "Y = y.reshape(n[3], m)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "713d8c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 1, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a925fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120d826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(arr):\n",
    "  return 1 / (1 + np.exp(-1 * arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fe818a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid of 0: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"sigmoid of 0:\", sigmoid(0)) # should be 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8de3d055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid of 0: [0.73105858 0.88079708 0.95257413 0.98201379]\n"
     ]
    }
   ],
   "source": [
    "print(\"sigmoid of 0:\", sigmoid(np.array([1,2,3,4]))) # should be 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8272bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "\n",
    "# layer 1 calculations\n",
    "\n",
    "Z1 = W1 @ A0 + b1  # the @ means matrix multiplication\n",
    "\n",
    "assert Z1.shape == (n[1], m) # just checking if shapes are good\n",
    "A1 = sigmoid(Z1)\n",
    "\n",
    "# layer 2 calculations\n",
    "Z2 = W2 @ A1 + b2\n",
    "assert Z2.shape == (n[2], m)\n",
    "A2 = sigmoid(Z2)\n",
    "\n",
    "# layer 3 calculations\n",
    "Z3 = W3 @ A2 + b3\n",
    "assert Z3.shape == (n[3], m)\n",
    "A3 = sigmoid(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0a977fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "print(A3.shape) # prints out (1, 10)\n",
    "y_hat = A3      # y_hat is essentially the prediction of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d00798ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15162989, 0.15160572, 0.15160572, 0.15191451, 0.15160733,\n",
       "        0.15160572, 0.15160572, 0.15163314, 0.15160575, 0.15206947]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a2c97f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58055349, 0.58055349, 0.58055349, 0.58055349, 0.58055349,\n",
       "        0.58055349, 0.58055349, 0.58055349, 0.58055349, 0.58055349]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64be76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. create network architecture\n",
    "L = 3\n",
    "n = [2, 3, 3, 1]\n",
    "\n",
    "# 2. create weights and biases\n",
    "W1 = np.random.randn(n[1], n[0])\n",
    "W2 = np.random.randn(n[2], n[1])\n",
    "W3 = np.random.randn(n[3], n[2])\n",
    "b1 = np.random.randn(n[1], 1)\n",
    "b2 = np.random.randn(n[2], 1)\n",
    "b3 = np.random.randn(n[3], 1)\n",
    "\n",
    "# 3. create training data and labels\n",
    "def prepare_data():\n",
    "  X = np.array([\n",
    "      [150, 70],\n",
    "      [254, 73],\n",
    "      [312, 68],\n",
    "      [120, 60],\n",
    "      [154, 61],\n",
    "      [212, 65],\n",
    "      [216, 67],\n",
    "      [145, 67],\n",
    "      [184, 64],\n",
    "      [130, 69]\n",
    "  ])\n",
    "  y = np.array([0,1,1,0,0,1,1,0,1,0])\n",
    "  m = 10\n",
    "  A0 = X.T\n",
    "  Y = y.reshape(n[L], m)\n",
    "\n",
    "  return A0, Y\n",
    "\n",
    "# 4. create activation function\n",
    "def sigmoid(arr):\n",
    "  return 1 / (1 + np.exp(-1 * arr))\n",
    "\n",
    "# 5. create feed forward process\n",
    "def feed_forward(A0):\n",
    "\n",
    "  # layer 1 calculations\n",
    "  Z1 = W1 @ A0 + b1\n",
    "  A1 = sigmoid(Z1)\n",
    "\n",
    "  # layer 2 calculations\n",
    "  Z2 = W2 @ A1 + b2\n",
    "  A2 = sigmoid(Z2)\n",
    "\n",
    "  # layer 3 calculations\n",
    "  Z3 = W3 @ A2 + b3\n",
    "  A3 = sigmoid(Z3)\n",
    "  \n",
    "  y_hat = A3\n",
    "  return y_hat\n",
    "\n",
    "A0, Y = prepare_data()\n",
    "y_hat = feed_forward(A0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7f73d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53944338, 0.53944338, 0.53944338, 0.53944338, 0.53944338,\n",
       "        0.53944338, 0.53944338, 0.53944338, 0.53944338, 0.53944338]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f93c8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_hat, y):\n",
    "  \"\"\"\n",
    "  y_hat should be a n^L x m matrix\n",
    "  y should be a n^L x m matrix\n",
    "  \"\"\"\n",
    "  # 1. losses is a n^L x m\n",
    "  losses = - ( (y * np.log(y_hat)) + (1 - y)*np.log(1 - y_hat) )\n",
    "\n",
    "  m = y_hat.reshape(-1).shape[0]\n",
    "\n",
    "  # 2. summing across axis = 1 means we sum across rows, \n",
    "  #   making this a n^L x 1 matrix\n",
    "  summed_losses = (1 / m) * np.sum(losses, axis=1)\n",
    "\n",
    "  # 3. unnecessary, but useful if working with more than one node\n",
    "  #   in output layer\n",
    "  return np.sum(summed_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e458ffd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6962684626408933)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(y_hat, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2294141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "L = 3\n",
    "n = [2, 3, 3, 1]\n",
    "W1 = np.random.randn(n[1], n[0])\n",
    "W2 = np.random.randn(n[2], n[1])\n",
    "W3 = np.random.randn(n[3], n[2])\n",
    "b1 = np.random.randn(n[1], 1)\n",
    "b2 = np.random.randn(n[2], 1)\n",
    "b3 = np.random.randn(n[3], 1)\n",
    "\n",
    "def prepare_data():\n",
    "  X = np.array([\n",
    "      [150, 70],\n",
    "      [254, 73],\n",
    "      [312, 68],\n",
    "      [120, 60],\n",
    "      [154, 61],\n",
    "      [212, 65],\n",
    "      [216, 67],\n",
    "      [145, 67],\n",
    "      [184, 64],\n",
    "      [130, 69]\n",
    "  ])\n",
    "  y = np.array([0,1,1,0,0,1,1,0,1,0])\n",
    "  m = 10\n",
    "  A0 = X.T\n",
    "  Y = y.reshape(n[L], m)\n",
    "\n",
    "  return A0, Y, m\n",
    "\n",
    "def cost(y_hat, y):\n",
    "  \"\"\"\n",
    "  y_hat should be a n^L x m matrix\n",
    "  y should be a n^L x m matrix\n",
    "  \"\"\"\n",
    "  # 1. losses is a n^L x m\n",
    "  losses = - ( (y * np.log(y_hat)) + (1 - y)*np.log(1 - y_hat) )\n",
    "\n",
    "  m = y_hat.reshape(-1).shape[0]\n",
    "\n",
    "  # 2. summing across axis = 1 means we sum across rows, \n",
    "  #   making this a n^L x 1 matrix\n",
    "  summed_losses = (1 / m) * np.sum(losses, axis=1)\n",
    "\n",
    "  # 3. unnecessary, but useful if working with more than one node\n",
    "  #   in output layer\n",
    "  return np.sum(summed_losses)\n",
    "\n",
    "def g(z):\n",
    "  return 1 / (1 + np.exp(-1 * z))\n",
    "\n",
    "def feed_forward(A0):\n",
    "  # layer 1 calculations\n",
    "  Z1 = W1 @ A0 + b1\n",
    "  A1 = g(Z1)\n",
    "\n",
    "  # layer 2 calculations\n",
    "  Z2 = W2 @ A1 + b2\n",
    "  A2 = g(Z2)\n",
    "\n",
    "  # layer 3 calculations\n",
    "  Z3 = W3 @ A2 + b3\n",
    "  A3 = g(Z3)\n",
    "\n",
    "  cache = {\n",
    "      \"A0\": A0,\n",
    "      \"A1\": A1,\n",
    "      \"A2\": A2\n",
    "  }\n",
    "\n",
    "  return A3, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3048098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A0, Y, m = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2337334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_layer_3(y_hat, Y, m, A2, W3):\n",
    "  A3 = y_hat\n",
    "  \n",
    "  # step 1. calculate dC/dZ3 using shorthand we derived earlier\n",
    "  dC_dZ3 = (1/m) * (A3 - Y)\n",
    "  assert dC_dZ3.shape == (n[3], m)\n",
    "\n",
    "\n",
    "  # step 2. calculate dC/dW3 = dC/dZ3 * dZ3/dW3 \n",
    "  #   we matrix multiply dC/dZ3 with (dZ3/dW3)^T\n",
    "  dZ3_dW3 = A2\n",
    "  assert dZ3_dW3.shape == (n[2], m)\n",
    "\n",
    "  dC_dW3 = dC_dZ3 @ dZ3_dW3.T\n",
    "  assert dC_dW3.shape == (n[3], n[2])\n",
    "\n",
    "  # step 3. calculate dC/db3 = np.sum(dC/dZ3, axis=1, keepdims=True)\n",
    "  dC_db3 = np.sum(dC_dZ3, axis=1, keepdims=True)\n",
    "  assert dC_db3.shape == (n[3], 1)\n",
    "\n",
    "  # step 4. calculate propagator dC/dA2 = dC/dZ3 * dZ3/dA2\n",
    "  dZ3_dA2 = W3 \n",
    "  dC_dA2 = W3.T @ dC_dZ3\n",
    "  assert dC_dA2.shape == (n[2], m)\n",
    "\n",
    "  return dC_dW3, dC_db3, dC_dA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7eaaf745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_layer_2(propagator_dC_dA2, A1, A2, W2):\n",
    "\n",
    "  # step 1. calculate dC/dZ2 = dC/dA2 * dA2/dZ2\n",
    "\n",
    "  # use sigmoid derivation to arrive at this answer:\n",
    "  #   sigmoid'(z) = sigmoid(z) * (1 - sigmoid(z))\n",
    "  #     and if a = sigmoid(z), then sigmoid'(z) = a * (1 - a)\n",
    "  dA2_dZ2 = A2 * (1 - A2)\n",
    "  dC_dZ2 = propagator_dC_dA2 * dA2_dZ2\n",
    "  assert dC_dZ2.shape == (n[2], m)\n",
    "\n",
    "\n",
    "  # step 2. calculate dC/dW2 = dC/dZ2 * dZ2/dW2 \n",
    "  dZ2_dW2 = A1\n",
    "  assert dZ2_dW2.shape == (n[1], m)\n",
    "\n",
    "  dC_dW2 = dC_dZ2 @ dZ2_dW2.T\n",
    "  assert dC_dW2.shape == (n[2], n[1])\n",
    "\n",
    "  # step 3. calculate dC/db2 = np.sum(dC/dZ2, axis=1, keepdims=True)\n",
    "  dC_db2 = np.sum(dC_dW2, axis=1, keepdims=True)\n",
    "  assert dC_db2.shape == (n[2], 1)\n",
    "\n",
    "  # step 4. calculate propagator dC/dA1 = dC/dZ2 * dZ2/dA1\n",
    "  dZ2_dA1 = W2\n",
    "  dC_dA1 = W2.T @ dC_dZ2\n",
    "  assert dC_dA1.shape == (n[2], m)\n",
    "\n",
    "  return dC_dW2, dC_db2, dC_dA1\n",
    "\n",
    "def backprop_layer_1(propagator_dC_dA1, A1, A0, W1):\n",
    "\n",
    "  # step 1. calculate dC/dZ1 = dC/dA1 * dA1/dZ1\n",
    "\n",
    "  # use sigmoid derivation to arrive at this answer:\n",
    "  #   sigmoid'(z) = sigmoid(z) * (1 - sigmoid(z))\n",
    "  #     and if a = sigmoid(z), then sigmoid'(z) = a * (1 - a)\n",
    "  dA1_dZ1 = A1 * (1 - A1)\n",
    "  dC_dZ1 = propagator_dC_dA1 * dA1_dZ1\n",
    "  assert dC_dZ1.shape == (n[1], m)\n",
    "\n",
    "\n",
    "  # step 2. calculate dC/dW1 = dC/dZ1 * dZ1/dW1 \n",
    "  dZ1_dW1 = A0\n",
    "  assert dZ1_dW1.shape == (n[0], m)\n",
    "\n",
    "  dC_dW1 = dC_dZ1 @ dZ1_dW1.T\n",
    "  assert dC_dW1.shape == (n[1], n[0])\n",
    "\n",
    "  # step 3. calculate dC/db1 = np.sum(dC/dZ1, axis=1, keepdims=True)\n",
    "  dC_db1 = np.sum(dC_dW1, axis=1, keepdims=True)\n",
    "  assert dC_db1.shape == (n[1], 1)\n",
    "\n",
    "  return dC_dW1, dC_db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3477f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, cache = feed_forward(A0)\n",
    "\n",
    "dC_dW3, dC_db3, dC_dA2 = backprop_layer_3(\n",
    "    y_hat, \n",
    "    Y, \n",
    "    m, \n",
    "    A2= cache[\"A2\"], \n",
    "    W3= W3\n",
    ")\n",
    "\n",
    "dC_dW2, dC_db2, dC_dA1 = backprop_layer_2(\n",
    "    propagator_dC_dA2=dC_dA2, \n",
    "    A1=cache[\"A1\"],\n",
    "    A2=cache[\"A2\"],\n",
    "    W2=W2\n",
    ")\n",
    "\n",
    "dC_dW1, dC_db1 = backprop_layer_1(\n",
    "    propagator_dC_dA1=dC_dA1, \n",
    "    A1=cache[\"A1\"],\n",
    "    A0=cache[\"A0\"],\n",
    "    W1=W1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a681ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  # must use global keyword in order to modify global variables\n",
    "  global W3, W2, W1, b3, b2, b1\n",
    "\n",
    "  epochs = 1000 # training for 1000 iterations\n",
    "  alpha = 0.1 # set learning rate to 0.1\n",
    "  costs = [] # list to store costs\n",
    "\n",
    "  for e in range(epochs):\n",
    "    # 1. FEED FORWARD\n",
    "    y_hat, cache = feed_forward(A0)\n",
    "    \n",
    "    # 2. COST CALCULATION\n",
    "    error = cost(y_hat, Y)\n",
    "    costs.append(error)\n",
    "\n",
    "    # 3. BACKPROP CALCULATIONS\n",
    "\n",
    "    dC_dW3, dC_db3, dC_dA2 = backprop_layer_3(\n",
    "        y_hat, \n",
    "        Y, \n",
    "        m, \n",
    "        A2= cache[\"A2\"], \n",
    "        W3=W3\n",
    "    )\n",
    "\n",
    "    dC_dW2, dC_db2, dC_dA1 = backprop_layer_2(\n",
    "        propagator_dC_dA2=dC_dA2, \n",
    "        A1=cache[\"A1\"],\n",
    "        A2=cache[\"A2\"],\n",
    "        W2=W2\n",
    "    )\n",
    "\n",
    "    dC_dW1, dC_db1 = backprop_layer_1(\n",
    "        propagator_dC_dA1=dC_dA1, \n",
    "        A1=cache[\"A1\"],\n",
    "        A0=cache[\"A0\"],\n",
    "        W1=W1\n",
    "    )\n",
    "\n",
    "    # 4. UPDATE WEIGHTS\n",
    "    W3 = W3 - (alpha * dC_dW3)\n",
    "    W2 = W2 - (alpha * dC_dW2)\n",
    "    W1 = W1 - (alpha * dC_dW1)\n",
    "\n",
    "    b3 = b3 - (alpha * dC_db3)\n",
    "    b2 = b2 - (alpha * dC_db2)\n",
    "    b1 = b1 - (alpha * dC_db1)\n",
    "\n",
    "\n",
    "    if e % 20 == 0:\n",
    "      print(f\"epoch {e}: cost = {error:4f}\")\n",
    "  \n",
    "  return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2f3fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: cost = 0.796345\n",
      "epoch 20: cost = 0.689320\n",
      "epoch 40: cost = 0.667795\n",
      "epoch 60: cost = 0.657773\n",
      "epoch 80: cost = 0.649419\n",
      "epoch 100: cost = 0.641128\n",
      "epoch 120: cost = 0.632395\n",
      "epoch 140: cost = 0.622897\n",
      "epoch 160: cost = 0.612365\n",
      "epoch 180: cost = 0.600556\n",
      "epoch 200: cost = 0.587264\n",
      "epoch 220: cost = 0.572336\n",
      "epoch 240: cost = 0.668892\n",
      "epoch 260: cost = 0.667532\n",
      "epoch 280: cost = 0.666282\n",
      "epoch 300: cost = 0.665578\n",
      "epoch 320: cost = 0.541828\n",
      "epoch 340: cost = 0.666132\n",
      "epoch 360: cost = 0.661655\n",
      "epoch 380: cost = 0.660381\n",
      "epoch 400: cost = 0.659742\n",
      "epoch 420: cost = 0.659148\n",
      "epoch 440: cost = 0.658553\n",
      "epoch 460: cost = 0.657957\n",
      "epoch 480: cost = 0.657362\n",
      "epoch 500: cost = 0.656770\n",
      "epoch 520: cost = 0.656181\n",
      "epoch 540: cost = 0.655595\n",
      "epoch 560: cost = 0.655014\n",
      "epoch 580: cost = 0.654436\n",
      "epoch 600: cost = 0.653864\n",
      "epoch 620: cost = 0.653296\n",
      "epoch 640: cost = 0.652734\n",
      "epoch 660: cost = 0.652177\n",
      "epoch 680: cost = 0.651627\n",
      "epoch 700: cost = 0.651082\n",
      "epoch 720: cost = 0.650544\n",
      "epoch 740: cost = 0.650013\n",
      "epoch 760: cost = 0.649488\n",
      "epoch 780: cost = 0.648971\n",
      "epoch 800: cost = 0.648459\n",
      "epoch 820: cost = 0.647952\n",
      "epoch 840: cost = 0.507265\n",
      "epoch 860: cost = 0.693669\n",
      "epoch 880: cost = 0.693191\n",
      "epoch 900: cost = 0.693151\n",
      "epoch 920: cost = 0.693147\n",
      "epoch 940: cost = 0.693147\n",
      "epoch 960: cost = 0.693147\n",
      "epoch 980: cost = 0.693147\n"
     ]
    }
   ],
   "source": [
    "costs = train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i-do-it-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
